"""
ROI Metrics Tool - Calculate value delivered to customers

Tracks:
- Time saved from duplicate prevention
- Coordination efficiency
- Knowledge sharing metrics
- Cost savings estimates
"""

from typing import Dict, Any, Sequence, Optional
from mcp.types import TextContent
from datetime import datetime, timedelta
from .utils import success_response, error_response
from .decorators import mcp_tool
from src.logging_utils import get_logger
from .shared import get_mcp_server

logger = get_logger(__name__)


class SimpleDiscovery:
    """Simple wrapper for discovery nodes to extract needed attributes"""
    def __init__(self, node):
        self.id = node.id if hasattr(node, 'id') else getattr(node, 'id', None)
        self.agent_id = node.agent_id if hasattr(node, 'agent_id') else getattr(node, 'agent_id', None)
        self.related_to = node.related_to if hasattr(node, 'related_to') else getattr(node, 'related_to', [])
        self.tags = node.tags if hasattr(node, 'tags') else getattr(node, 'tags', [])


@mcp_tool("get_roi_metrics", timeout=15.0)
async def handle_get_roi_metrics(arguments: Dict[str, Any]) -> Sequence[TextContent]:
    """
    Calculate ROI metrics showing value delivered by multi-agent coordination.
    
    Returns:
    - Time saved (from duplicate prevention)
    - Coordination efficiency score
    - Knowledge sharing metrics
    - Cost savings estimates
    
    Example:
    {
      "time_saved_hours": 12.5,
      "duplicates_prevented": 15,
      "coordination_efficiency": 0.85,
      "cost_savings_estimate": 2500
    }
    """
    try:
        from src.knowledge_graph import get_knowledge_graph
        from .shared import get_mcp_server
        
        mcp_server = get_mcp_server()
        graph = await get_knowledge_graph()
        
        # Get knowledge graph stats
        kg_stats = await graph.get_stats()
        total_discoveries = kg_stats.get("total_discoveries", 0)
        
        # Get agent stats
        await mcp_server.load_metadata_async()
        total_agents = len(mcp_server.agent_metadata)
        active_agents = sum(1 for meta in mcp_server.agent_metadata.values() 
                           if getattr(meta, 'status', 'active') in ['active', 'waiting_input'])
        
        # Calculate duplicates prevented
        # Estimate: If agents searched before starting work, they found existing discoveries
        # We can estimate this by looking at discovery relationships (related_to)
        duplicates_prevented = 0
        time_saved_hours = 0.0
        all_discoveries = []
        
        try:
            # Get all discoveries using graph.query() method
            # Query with empty filters to get all discoveries
            all_discoveries_raw = await graph.query(
                agent_id=None,
                tags=None,
                type=None,
                severity=None,
                status=None,
                limit=1000
            )
            
            # Convert to simple objects with needed attributes
            all_discoveries = [SimpleDiscovery(node) for node in all_discoveries_raw]
            
            # Count discoveries that found similar work (duplicate prevention)
            discoveries_with_relations = 0
            for disc in all_discoveries:
                if hasattr(disc, 'related_to') and disc.related_to:
                    discoveries_with_relations += len(disc.related_to)
                    duplicates_prevented += len(disc.related_to)
            
            # Estimate time saved
            # Average: 30 minutes per duplicate prevented (conservative)
            # This includes: discovery time, implementation time, testing time
            time_saved_hours = duplicates_prevented * 0.5
            
        except Exception as e:
            logger.debug(f"Could not calculate duplicate prevention: {e}")
            # Fallback: Estimate based on total discoveries
            # Assume 20% of discoveries prevented duplicates
            duplicates_prevented = int(total_discoveries * 0.2)
            time_saved_hours = duplicates_prevented * 0.5
        
        # Calculate coordination efficiency
        # Based on:
        # - Cross-agent discovery sharing (agents finding each other's work)
        # - Knowledge graph connectivity (discoveries linked together)
        # - Agent collaboration (multiple agents contributing to same topics)
        
        coordination_efficiency = 0.0
        try:
            # Get discoveries with cross-agent relationships
            cross_agent_sharing = 0
            agent_contributions = {}
            
            # Use all_discoveries if available, otherwise sample from graph
            discoveries_sample = all_discoveries[:100] if all_discoveries else []
            if not discoveries_sample and total_discoveries > 0:
                # Fallback: Get sample using graph.query()
                try:
                    sample_raw = await graph.query(
                        agent_id=None,
                        tags=None,
                        type=None,
                        severity=None,
                        status=None,
                        limit=100
                    )
                    discoveries_sample = [SimpleDiscovery(node) for node in sample_raw]
                except Exception:
                    discoveries_sample = []
            
            for disc in discoveries_sample:
                agent_id = getattr(disc, 'agent_id', None)
                if agent_id:
                    agent_contributions[agent_id] = agent_contributions.get(agent_id, 0) + 1
                
                # Check if discovery has relationships to other agents' work
                if hasattr(disc, 'related_to') and disc.related_to:
                    cross_agent_sharing += 1
            
            # Coordination efficiency formula:
            # - Base: 0.5 (some coordination happening)
            # - +0.2 if cross-agent sharing > 20% of discoveries
            # - +0.2 if multiple agents contributing (not just one agent)
            # - +0.1 if total discoveries > 10 (active knowledge graph)
            
            sample_size = len(discoveries_sample)
            if sample_size > 0:
                sharing_ratio = cross_agent_sharing / sample_size
                coordination_efficiency = 0.5
                
                if sharing_ratio > 0.2:
                    coordination_efficiency += 0.2
                
                if len(agent_contributions) > 1:
                    coordination_efficiency += 0.2
                
                if total_discoveries > 10:
                    coordination_efficiency += 0.1
                
                coordination_efficiency = min(coordination_efficiency, 1.0)
            else:
                coordination_efficiency = 0.0
                
        except Exception as e:
            logger.debug(f"Could not calculate coordination efficiency: {e}")
            coordination_efficiency = 0.5  # Default moderate efficiency
        
        # Calculate cost savings estimate
        # Assumption: Average developer cost = $100/hour
        # Time saved Ã— hourly rate = cost savings
        hourly_rate = arguments.get("hourly_rate", 100)  # Default $100/hour
        cost_savings_estimate = time_saved_hours * hourly_rate
        
        # Calculate knowledge sharing metrics
        discoveries_for_stats = all_discoveries[:100] if all_discoveries else []
        if not discoveries_for_stats and total_discoveries > 0:
            try:
                stats_raw = await graph.query(
                    agent_id=None,
                    tags=None,
                    type=None,
                    severity=None,
                    status=None,
                    limit=100
                )
                discoveries_for_stats = [SimpleDiscovery(node) for node in stats_raw]
            except Exception:
                discoveries_for_stats = []
        
        unique_agents_contributing = len(set(
            getattr(disc, 'agent_id', None) 
            for disc in discoveries_for_stats
            if hasattr(disc, 'agent_id') and disc.agent_id
        ))
        
        # Average discoveries per agent
        avg_discoveries_per_agent = total_discoveries / max(active_agents, 1)
        
        # Build response
        roi_data = {
            "time_saved": {
                "hours": round(time_saved_hours, 2),
                "days": round(time_saved_hours / 8, 2),
                "description": f"Estimated time saved from preventing {duplicates_prevented} duplicate work items"
            },
            "duplicates_prevented": duplicates_prevented,
            "coordination_efficiency": {
                "score": round(coordination_efficiency, 2),
                "percentage": round(coordination_efficiency * 100, 1),
                "description": "Measures how well agents coordinate and share knowledge (0.0 = no coordination, 1.0 = perfect coordination)"
            },
            "knowledge_sharing": {
                "total_discoveries": total_discoveries,
                "unique_agents_contributing": unique_agents_contributing,
                "avg_discoveries_per_agent": round(avg_discoveries_per_agent, 2),
                "description": "Knowledge graph activity metrics"
            },
            "cost_savings": {
                "estimated_usd": round(cost_savings_estimate, 2),
                "hourly_rate_used": hourly_rate,
                "description": f"Estimated cost savings at ${hourly_rate}/hour developer rate"
            },
            "system_health": {
                "total_agents": total_agents,
                "active_agents": active_agents,
                "coordination_active": coordination_efficiency > 0.3
            },
            "calculation_method": {
                "duplicates_estimate": "Based on discovery relationships (related_to) - indicates similar work found before starting",
                "time_per_duplicate": "0.5 hours (conservative estimate: discovery + implementation + testing)",
                "coordination_formula": "Base 0.5 + sharing bonus (0.2) + multi-agent bonus (0.2) + activity bonus (0.1)",
                "cost_assumption": f"${hourly_rate}/hour developer rate (customizable via hourly_rate parameter)"
            }
        }
        
        return success_response(roi_data)
        
    except Exception as e:
        logger.error(f"Error calculating ROI metrics: {e}", exc_info=True)
        return [error_response(
            f"Failed to calculate ROI metrics: {str(e)}",
            error_code="ROI_CALCULATION_ERROR",
            error_category="system_error",
            recovery={
                "action": "Check system health and try again",
                "related_tools": ["health_check", "list_knowledge_graph"],
                "workflow": [
                    "1. Verify knowledge graph is accessible",
                    "2. Check agent metadata is loaded",
                    "3. Retry get_roi_metrics"
                ]
            }
        )]

