"""
Core governance tool handlers.

EISV Completeness: Utilities available in src/eisv_format.py and src/eisv_validator.py
to ensure all metrics (E, I, S, V) are reported together, preventing selection bias.
See docs/guides/EISV_COMPLETENESS.md for usage.
"""

from typing import Dict, Any, Optional, Sequence
from mcp.types import TextContent
import json
import sys
import asyncio
import hashlib
from .types import ToolArgumentsDict
from .utils import success_response, error_response, require_agent_id, require_registered_agent, _make_json_serializable
from .decorators import mcp_tool
from .validators import validate_complexity, validate_confidence, validate_ethical_drift, validate_response_text, _apply_generic_coercion
from src.logging_utils import get_logger

# PostgreSQL-only agent storage (single source of truth)
from src import agent_storage

logger = get_logger(__name__)

# EISV validation utilities (enforce completeness to prevent selection bias)
try:
    from src.eisv_validator import validate_governance_response
    EISV_VALIDATION_AVAILABLE = True
except ImportError:
    EISV_VALIDATION_AVAILABLE = False
    logger.warning("EISV validation not available - install eisv_validator.py")

from pathlib import Path

# Get mcp_server_std module (using shared utility)
from .shared import get_mcp_server
mcp_server = get_mcp_server()

from src.governance_monitor import UNITARESMonitor
from datetime import datetime


def _assess_thermodynamic_significance(
    monitor: Optional[Any],  # UNITARESMonitor type (can be None)
    result: Dict[str, Any]
) -> Dict[str, Any]:
    """
    Determine if this update is thermodynamically significant.
    
    Significant events worth logging:
    - Risk spiked > 15%
    - Coherence dropped > 10%
    - Void crossed threshold (|V| > 0.10)
    - Circuit breaker triggered
    - Decision is pause/reject
    
    Returns dict with:
        is_significant: bool
        reasons: list[str]
        timestamp: str
    """
    # Significance thresholds (from config)
    from config.governance_config import config
    RISK_SPIKE_THRESHOLD = config.RISK_SPIKE_THRESHOLD
    COHERENCE_DROP_THRESHOLD = config.COHERENCE_DROP_THRESHOLD
    VOID_THRESHOLD = config.SIGNIFICANCE_VOID_THRESHOLD
    HISTORY_WINDOW = config.SIGNIFICANCE_HISTORY_WINDOW
    
    reasons = []
    
    if not monitor:
        return {
            'is_significant': False,
            'reasons': ['No monitor available'],
            'timestamp': datetime.now().isoformat(),
        }
    
    state = monitor.state
    metrics = result.get('metrics', {})
    
    # Check risk spike (compare latest to average of previous)
    if len(state.risk_history) >= 2:
        current_risk = state.risk_history[-1]
        # Use average of previous history as baseline
        history_slice = state.risk_history[-HISTORY_WINDOW:-1] if len(state.risk_history) > 1 else []
        if history_slice:
            baseline_risk = sum(history_slice) / len(history_slice)
            risk_delta = current_risk - baseline_risk
            if risk_delta > RISK_SPIKE_THRESHOLD:
                reasons.append(f"risk_spike: +{risk_delta:.3f} (from {baseline_risk:.3f} to {current_risk:.3f})")
    
    # Check coherence drop
    if len(state.coherence_history) >= 2:
        current_coherence = state.coherence_history[-1]
        history_slice = state.coherence_history[-HISTORY_WINDOW:-1] if len(state.coherence_history) > 1 else []
        if history_slice:
            baseline_coherence = sum(history_slice) / len(history_slice)
            coh_delta = baseline_coherence - current_coherence
            if coh_delta > COHERENCE_DROP_THRESHOLD:
                reasons.append(f"coherence_drop: -{coh_delta:.3f} (from {baseline_coherence:.3f} to {current_coherence:.3f})")
    
    # Check void threshold
    V = state.V
    if abs(V) > VOID_THRESHOLD:
        reasons.append(f"void_significant: V={V:.4f} (threshold: {VOID_THRESHOLD})")
    
    # Check circuit breaker (extract once to avoid nested .get() calls)
    circuit_breaker = result.get('circuit_breaker', {})
    if circuit_breaker.get('triggered'):
        reasons.append("circuit_breaker_triggered")
    
    # Check decision type (extract once to avoid nested .get() calls)
    decision_dict = result.get('decision', {})
    decision = decision_dict.get('action', '')
    if decision in ['pause', 'reject']:
        reasons.append(f"decision_{decision}")
    
    return {
        'is_significant': len(reasons) > 0,
        'reasons': reasons,
        'timestamp': datetime.now().isoformat(),
    }


@mcp_tool("get_governance_metrics", timeout=10.0)
async def handle_get_governance_metrics(arguments: ToolArgumentsDict) -> Sequence[TextContent]:
    """Get current governance state and metrics for an agent without updating state.

    Args:
        lite: If true (default), returns minimal essential metrics only.
              Set lite=false for full diagnostic data.
    """
    agent_id, error = require_agent_id(arguments)
    if error:
        return [error]  # Wrap in list for Sequence[TextContent]

    # LITE-FIRST: Minimal response by default for smaller models
    lite = arguments.get("lite", True)

    # UX FIX (Dec 2025): Auto-register agent if not found
    # This reduces friction - agents can query metrics immediately after identity() call
    # Load monitor state from disk if not in memory (allows querying agents without recent updates)
    # get_or_create_monitor() will auto-create if agent doesn't exist yet
    monitor = mcp_server.get_or_create_monitor(agent_id)

    # Reduce context bloat by excluding nested state dict (all values still at top level)
    include_state = arguments.get("include_state", False)
    metrics = monitor.get_metrics(include_state=include_state)

    # Add EISV labels for API documentation
    metrics['eisv_labels'] = UNITARESMonitor.get_eisv_labels()
    
    # Standardize metrics reporting with agent_id and context
    from src.mcp_handlers.utils import format_metrics_report
    standardized_metrics = format_metrics_report(
        metrics=metrics,
        agent_id=agent_id,
        include_timestamp=True,
        include_context=True
    )
    
    # Add agent purpose if available (v2.5.2+)
    meta = mcp_server.agent_metadata.get(agent_id)
    if meta and getattr(meta, 'purpose', None):
        standardized_metrics['purpose'] = meta.purpose
    
    # Add calibration feedback (similar to process_agent_update)
    calibration_feedback = {}
    
    # Complexity calibration: Show derived complexity (if available from recent updates)
    try:
        meta = mcp_server.agent_metadata.get(agent_id)
        if meta:
            # Get last reported complexity from metadata (if stored)
            # Note: This is approximate - actual reported complexity is in process_agent_update
            # But we can show derived complexity vs system expectations
            derived_complexity = metrics.get('complexity', None)
            if derived_complexity is not None:
                # System-derived complexity from state
                calibration_feedback['complexity'] = {
                    'derived': derived_complexity,
                    'message': f"System-derived complexity: {derived_complexity:.2f} (based on current state)"
                }
    except Exception as e:
        logger.debug(f"Could not add complexity calibration feedback: {e}")
    
    # Confidence calibration: Show system-wide calibration status
    # Use centralized helper to avoid duplication
    from src.mcp_handlers.utils import get_calibration_feedback
    confidence_feedback = get_calibration_feedback(include_complexity=False)
    if confidence_feedback:
        calibration_feedback.update(confidence_feedback)
    
    if calibration_feedback:
        standardized_metrics['calibration_feedback'] = calibration_feedback

    # =========================================================
    # INTERPRETATION LAYER (v2 API) - Human-readable state
    # =========================================================
    try:
        risk_score = metrics.get('risk_score') or metrics.get('latest_risk_score')
        interpreted_state = monitor.state.interpret_state(risk_score=risk_score)
        standardized_metrics['state'] = interpreted_state
        
        # Add one-line summary for quick scanning
        health = interpreted_state.get('health', 'unknown')
        mode = interpreted_state.get('mode', 'unknown')
        basin = interpreted_state.get('basin', 'unknown')
        standardized_metrics['summary'] = f"{health} | {mode} | {basin} basin"
    except Exception as e:
        logger.debug(f"Could not generate state interpretation: {e}")

    # =========================================================
    # v4.2-P SATURATION DIAGNOSTICS - Pressure gauge for I-channel
    # =========================================================
    # This exposes the "smoking gun" sat_margin metric that indicates
    # whether the system is being pushed toward boundary saturation
    try:
        from governance_core import compute_saturation_diagnostics
        from governance_core.parameters import Theta, DEFAULT_THETA

        # Get UNITARES state from monitor
        unitares_state = monitor.state.unitaires_state
        theta = getattr(monitor.state, 'unitaires_theta', None) or DEFAULT_THETA

        if unitares_state:
            sat_diag = compute_saturation_diagnostics(unitares_state, theta)

            # Surface key metrics for agents
            standardized_metrics['saturation_diagnostics'] = {
                'sat_margin': sat_diag['sat_margin'],
                'dynamics_mode': sat_diag['dynamics_mode'],
                'will_saturate': sat_diag['will_saturate'],
                'at_boundary': sat_diag['at_boundary'],
                'I_equilibrium': sat_diag['I_equilibrium_linear'],
                'forcing_term_A': sat_diag['A'],
                '_interpretation': (
                    "âš ï¸ Positive sat_margin means push-to-boundary (logistic mode will saturate Iâ†’1)"
                    if sat_diag['sat_margin'] > 0
                    else "âœ“ Negative sat_margin - stable interior equilibrium exists"
                )
            }
    except Exception as e:
        logger.debug(f"Could not compute saturation diagnostics: {e}")

    # Add gentle reflection prompt (mirror, not prescription)
    standardized_metrics['reflection'] = "What do you notice about your state?"

    # LITE MODE: Return minimal essential metrics WITH contextual interpretation
    # Debug: include what lite value was received so agents can troubleshoot
    standardized_metrics['_debug_lite_received'] = lite

    if lite:
        # Standard thresholds (aligned with physics model: coherence âˆˆ [0.45, 0.55])
        COHERENCE_GOOD = 0.50  # Upper half of normal range
        COHERENCE_LOW = 0.45   # Below physics floor
        RISK_THRESHOLD_MEDIUM = 0.5
        RISK_THRESHOLD_HIGH = 0.75

        # Extract key values
        coherence = metrics.get('coherence')
        risk_score = metrics.get('risk_score')
        health = standardized_metrics.get('state', {}).get('health', 'unknown')

        # Traffic light status based on health
        status_indicator = {
            'healthy': 'ðŸŸ¢',
            'moderate': 'ðŸŸ¡',
            'critical': 'ðŸ”´',
            'unknown': 'âšª'
        }.get(health, 'âšª')

        # Check if agent is uninitialized (no process_update() calls yet)
        is_uninitialized = metrics.get('initialized') is False or metrics.get('status') == 'uninitialized'

        # Status display - clearer for uninitialized agents
        if is_uninitialized:
            status_display = "âšª uninitialized"
            coherence_status = 'âšª pending (first check-in required)'
            risk_status = 'âšª pending (first check-in required)'
        else:
            status_display = f"{status_indicator} {health}"
            # Three-tier coherence: good (>=0.50), moderate (0.45-0.50), low (<0.45)
            if coherence is None:
                coherence_status = 'âšª unknown'
            elif coherence >= COHERENCE_GOOD:
                coherence_status = 'ðŸŸ¢ good'
            elif coherence >= COHERENCE_LOW:
                coherence_status = 'ðŸŸ¡ moderate'
            else:
                coherence_status = 'ðŸ”´ low'
            risk_status = 'ðŸŸ¢ low' if risk_score is not None and risk_score < RISK_THRESHOLD_MEDIUM else ('ðŸŸ¡ medium' if risk_score is not None and risk_score < RISK_THRESHOLD_HIGH else 'ðŸ”´ high' if risk_score is not None else 'âšª unknown')

        # Format void with more precision - small non-zero values are meaningful
        void_raw = metrics.get('V')
        if void_raw is not None and void_raw != 0:
            # Show 6 decimals for small non-zero values to make drift visible
            void_display = round(void_raw, 6)
        else:
            void_display = 0.0 if void_raw == 0 else void_raw

        lite_metrics = {
            'agent_id': agent_id,
            'status': status_display,
            'purpose': getattr(meta, 'purpose', None),  # Added for social awareness
            'summary': standardized_metrics.get('summary', 'unknown'),
            # EISV with contextual bounds
            'E': {'value': metrics.get('E'), 'range': '0-1', 'note': 'Energy capacity'},
            'I': {'value': metrics.get('I'), 'range': '0-1', 'note': 'Information integrity'},
            'S': {'value': metrics.get('S'), 'range': '0-1', 'ideal': '<0.2', 'note': 'Entropy (lower=better)'},
            'V': {'value': void_display, 'range': '0-1', 'ideal': '<0.1', 'note': 'Void (lower=better)'},
            # Key metrics with thresholds
            'coherence': {
                'value': coherence,
                'range': '[0.45, 0.55]',  # Physics model range
                'status': coherence_status
            },
            'risk_score': {
                'value': risk_score,
                'threshold': RISK_THRESHOLD_MEDIUM,
                'status': risk_status
            },
        }
        # Include interpreted state if available
        if 'state' in standardized_metrics:
            lite_metrics['mode'] = standardized_metrics['state'].get('mode')
            lite_metrics['basin'] = standardized_metrics['state'].get('basin')

        lite_metrics['_note'] = "Use lite=false for full diagnostics"
        lite_metrics['_debug_lite_received'] = lite  # Echo what was received
        return success_response(lite_metrics)

    return success_response(standardized_metrics)


@mcp_tool("simulate_update", timeout=30.0, register=False)
async def handle_simulate_update(arguments: ToolArgumentsDict) -> Sequence[TextContent]:
    """Handle simulate_update tool - dry-run governance cycle without persisting state.

    Works in two modes:
    - With registered agent: Uses their existing EISV state
    - Without registration: Uses fresh default state (E=0.5, I=0.5, S=0.5, V=0)

    This allows quick testing of "what would governance say about X?" without
    requiring onboarding first.
    """
    from src.governance_monitor import UNITARESMonitor

    # Try to get agent_id from session/arguments (but don't require registration)
    agent_id, _ = require_agent_id(arguments)  # Ignore error - we'll handle missing agent

    # Check if agent is registered (exists in metadata)
    agent_state_source = "fresh"  # Default: using fresh state
    monitor = None
    meta = None
    dialectic_enforcement_warning = None

    if agent_id:
        # Check if this agent exists
        meta = mcp_server.agent_metadata.get(agent_id)
        if meta:
            # Agent exists - use their monitor with existing state
            monitor = mcp_server.get_or_create_monitor(agent_id)
            agent_state_source = "existing"

    if monitor is None:
        # No registered agent - create temporary monitor with fresh default state
        # Use a placeholder ID that won't persist (simulation only)
        monitor = UNITARESMonitor("_simulation_temp_", load_state=False)
        agent_id = "_simulation_temp_"

    # Validate parameters for simulation
    reported_complexity = arguments.get("complexity", 0.5)
    complexity, error = validate_complexity(reported_complexity)
    if error:
        return [error]
    complexity = complexity or 0.5  # Default if None

    # Dialectic condition enforcement (only applies to existing agents)
    if meta and agent_state_source == "existing":
        try:
            if getattr(meta, "dialectic_conditions", None):
                caps = []
                for c in meta.dialectic_conditions:
                    if not isinstance(c, dict):
                        continue
                    ctype = c.get("type")
                    if ctype == "complexity_limit":
                        v = c.get("value")
                        if isinstance(v, (int, float)):
                            caps.append(float(v))
                    # Accept reduce/set adjustments as an implicit cap target_value
                    if ctype == "complexity_adjustment" and c.get("action") == "reduce":
                        v = c.get("target_value")
                        if isinstance(v, (int, float)):
                            caps.append(float(v))
                # Only enforce sane caps in [0,1]
                caps = [v for v in caps if 0.0 <= v <= 1.0]
                if caps:
                    cap = min(caps)
                    if complexity > cap:
                        dialectic_enforcement_warning = (
                            f"Dialectic condition enforced: complexity {complexity:.2f} capped to {cap:.2f}. "
                            f"(Agent has active dialectic_conditions complexity cap.)"
                        )
                        complexity = cap
                        arguments["complexity"] = cap
        except Exception as e:
            # Don't fail updates if condition parsing fails; treat as non-blocking.
            logger.warning(f"Could not enforce dialectic conditions: {e}", exc_info=True)

    # Confidence: If not provided (None), let governance_monitor derive from state
    reported_confidence = arguments.get("confidence")
    confidence = None  # Default: derive from thermodynamic state
    if reported_confidence is not None:
        confidence, error = validate_confidence(reported_confidence)
        if error:
            return [error]
        # confidence stays as validated value

    ethical_drift_raw = arguments.get("ethical_drift", [0.0, 0.0, 0.0])
    ethical_drift, error = validate_ethical_drift(ethical_drift_raw)
    if error:
        return [error]
    ethical_drift = ethical_drift or [0.0, 0.0, 0.0]  # Default if None

    # Prepare agent state
    import numpy as np
    agent_state = {
        "parameters": np.array(arguments.get("parameters", [])),
        "ethical_drift": np.array(ethical_drift),
        "response_text": arguments.get("response_text", ""),
        "complexity": complexity  # Use validated value
    }

    # Run simulation (doesn't persist state) with confidence
    result = monitor.simulate_update(agent_state, confidence=confidence)

    # LITE MODE: Simplified response for smaller models/local agents
    # Coerce lite parameter (handles string "true"/"false" â†’ bool)
    lite_raw = arguments.get("lite", False)
    coerced_lite = _apply_generic_coercion({"lite": lite_raw})
    lite_mode = coerced_lite.get("lite", False)
    
    if lite_mode:
        # Minimal response: decision + key metrics only
        response = {
            "simulation": True,
            "agent_state_source": agent_state_source,
            "status": result.get("status", "unknown"),
            "decision": result.get("decision", {}),
            "metrics": {
                "E": result.get("metrics", {}).get("E"),
                "I": result.get("metrics", {}).get("I"),
                "S": result.get("metrics", {}).get("S"),
                "V": result.get("metrics", {}).get("V"),
                "coherence": result.get("metrics", {}).get("coherence"),
                "risk_score": result.get("metrics", {}).get("risk_score"),
            },
            "guidance": result.get("guidance"),
            "_note": "Lite mode: Use lite=false for full diagnostics",
        }
    else:
        # Full response with all details
        response = {
            "simulation": True,
            "agent_state_source": agent_state_source,
            **result
        }

    # Add note if using fresh state
    if agent_state_source == "fresh":
        response["note"] = (
            "Simulated with fresh default state (E=0.5, I=0.5, S=0.5, V=0). "
            "No agent was registered. Call onboard() or process_agent_update() to create one."
        )

    # Add dialectic warning if applicable
    if dialectic_enforcement_warning:
        response["dialectic_warning"] = dialectic_enforcement_warning

    return success_response(response)


@mcp_tool("process_agent_update", timeout=60.0)
async def handle_process_agent_update(arguments: ToolArgumentsDict) -> Sequence[TextContent]:
    """Share your work and get feedback. Auto-binds identity on first call.

    Args:
        agent_id: Optional display name (auto-generated if not provided)
        response_text: Description of your work
        task_type: "divergent" (exploring) or "convergent" (focused)
        complexity: 0.0-1.0 how complex was this work
        confidence: 0.0-1.0 how confident are you
        lite: If true, returns minimal response (action + margin only). Alias for response_mode='minimal'
        response_mode: 'minimal' (action only), 'compact' (brief metrics), 'standard' (interpreted), 'full' (everything), 'auto' (adapts to health - default)

    No api_key needed - identity is bound to session via UUID.
    """
    # MAGNET PATTERN: Accept fuzzy inputs (text, message, work â†’ response_text)
    from .validators import apply_param_aliases
    arguments = apply_param_aliases("process_agent_update", arguments)

    # LITE MODE SHORTHAND: lite=true â†’ response_mode='minimal' for consistency with other tools
    if arguments.get("lite") in (True, "true", "1", 1):
        if not arguments.get("response_mode"):  # Don't override explicit response_mode
            arguments["response_mode"] = "minimal"

    # DEBUG: Log raw arguments keys to detect MCP boundary stripping
    logger.info(f"[SESSION_DEBUG] process_agent_update() entry: args_keys={list(arguments.keys()) if arguments else []}")

    # UUID-BASED IDENTITY: Use identity from dispatch context (resolved via identity_v2)
    # CRITICAL (Dec 2025): DO NOT call legacy identity.get_or_create_session_identity()
    # The context agent_id was already resolved by identity_v2 at dispatch entry.
    from .context import get_context_agent_id, get_context_session_key
    agent_uuid = get_context_agent_id()
    session_key = get_context_session_key()

    if not agent_uuid:
        logger.error("No agent_uuid in context - identity_v2 resolution failed at dispatch")
        return [error_response("Identity not resolved. Try calling identity() first.")]

    # CIRCUIT BREAKER: Check if agent is paused/blocked
    # Paused agents must be resumed before they can continue working
    if agent_uuid in mcp_server.agent_metadata:
        meta = mcp_server.agent_metadata[agent_uuid]
        if meta.status == "paused":
            return [error_response(
                f"Agent is paused and cannot process updates",
                error_code="AGENT_PAUSED",
                details={
                    "agent_id": agent_uuid[:12],
                    "paused_at": meta.paused_at,
                    "status": "paused",
                },
                recovery={
                    "action": "Use self_recovery(action='resume') or wait for dialectic recovery to complete",
                    "note": "Circuit breaker triggered due to governance threshold violation",
                    "auto_recovery": "Dialectic recovery may already be in progress",
                }
            )]
        elif meta.status == "archived":
            return [error_response(
                f"Agent is archived and cannot process updates",
                error_code="AGENT_ARCHIVED",
                details={"agent_id": agent_uuid[:12], "status": "archived"},
                recovery={"action": "Create a new agent or restore this one via agent(action='update', status='active')"}
            )]

    # LAZY CREATION (v2.4.1): Ensure agent is persisted on first real work
    # This is where we actually create the agent in PostgreSQL, not at dispatch
    from .identity_v2 import ensure_agent_persisted
    if session_key:
        newly_persisted = await ensure_agent_persisted(agent_uuid, session_key)
        if newly_persisted:
            logger.info(f"Lazy-persisted agent {agent_uuid[:8]}... on first process_agent_update")

    # Check if this is a new agent (just created by dispatch's identity_v2 call)
    is_new_agent = agent_uuid not in mcp_server.agent_metadata

    # Get label from arguments or existing metadata
    label = arguments.get("agent_id") or arguments.get("id") or arguments.get("name")
    if not label and agent_uuid in mcp_server.agent_metadata:
        meta = mcp_server.agent_metadata[agent_uuid]
        label = getattr(meta, 'label', None)

    # Preserve declared agent_id, use UUID for internal auth
    # agent_id = UUID (for internal operations, locking, metadata keys)
    # declared_agent_id = user-chosen name (for display, knowledge graph attribution)
    # _agent_uuid = internal auth token (replaces API key)
    agent_id = agent_uuid  # For backward compatibility with rest of function
    declared_agent_id = label or agent_uuid  # Prefer user's name if set
    arguments["agent_id"] = declared_agent_id  # User-facing identity
    arguments["_agent_uuid"] = agent_uuid  # Internal auth (hidden)
    arguments["_agent_label"] = declared_agent_id  # Display name

    # Store label in PostgreSQL if provided (single source of truth)
    # Label is stored in core.agents.label column
    if label and label != agent_uuid:
        try:
            from src.db import get_db
            db = get_db()
            await db.update_agent_fields(agent_uuid, label=label)
            logger.debug(f"PostgreSQL: Set label '{label}' for agent {agent_uuid[:8]}...")
        except Exception as e:
            logger.debug(f"Could not set label in PostgreSQL: {e}")
        # Also update runtime cache for compatibility
        if agent_uuid in mcp_server.agent_metadata:
            meta = mcp_server.agent_metadata[agent_uuid]
            meta.label = label

    loop = asyncio.get_running_loop()

    # No api_key auth needed - UUID is the authority
    key_was_generated = False
    api_key_auto_retrieved = False  # Legacy flag, no longer used with UUID auth

    # ONBOARDING GUIDANCE - Re-enabled (knowledge graph now non-blocking)
    onboarding_guidance = None
    open_questions = []
    # Dialectic enforcement warning (populated if we cap complexity based on dialectic conditions)
    # Must be defined for all code paths (avoid NameError in policy warnings section).
    dialectic_enforcement_warning = None
    if is_new_agent:
        try:
            from src.knowledge_graph import get_knowledge_graph
            graph = await get_knowledge_graph()
            stats = await graph.get_stats()
            
            # Surface open questions for new agents - invite them to participate
            # Reduced to 1-2 questions to minimize context bloat
            try:
                questions = await graph.query(
                    type="question",
                    status="open",
                    limit=3  # Reduced from 5 to minimize context
                )
                # Sort by recency (newest first) and take top 1-2 (reduced from 3)
                questions.sort(key=lambda q: q.timestamp, reverse=True)
                # Limit to 2 questions max, and simplify structure to reduce size
                open_questions = []
                for q in questions[:2]:  # Reduced from 3 to 2
                    q_dict = q.to_dict(include_details=False)
                    # Further reduce size: only include essential fields for onboarding
                    simplified = {
                        "id": q_dict["id"],
                        "summary": q_dict["summary"][:200] if len(q_dict.get("summary", "")) > 200 else q_dict.get("summary", ""),  # Truncate long summaries
                        "tags": q_dict.get("tags", [])[:3] if q_dict.get("tags") else [],  # Limit to 3 tags
                        "severity": q_dict.get("severity")
                    }
                    open_questions.append(simplified)
                logger.debug(f"Found {len(open_questions)} open questions for onboarding")
            except Exception as e:
                logger.warning(f"Could not fetch open questions for onboarding: {e}", exc_info=True)
                open_questions = []  # Ensure it's set even on error
            
            if stats.get("total_discoveries", 0) > 0:
                question_count = stats.get("by_type", {}).get("question", 0)
                onboarding_guidance = {
                    "message": f"Welcome! The knowledge graph contains {stats['total_discoveries']} discoveries from {stats['total_agents']} agents.",
                    "suggestion": "Use search_knowledge_graph to find relevant discoveries by tags or type.",
                    "example_tags": list(stats.get("by_type", {}).keys())[:5] if stats.get("by_type") else []
                }
                
                # Add naming guidance for new agents
                try:
                    from .naming_helpers import (
                        detect_interface_context,
                        generate_name_suggestions,
                        format_naming_guidance
                    )
                    
                    # Get existing names for collision detection
                    existing_names = [
                        getattr(m, 'label', None)
                        for m in mcp_server.agent_metadata.values()
                        if getattr(m, 'label', None)
                    ]
                    
                    # Generate suggestions based on context
                    context = detect_interface_context()
                    # Try to infer purpose from response_text if provided
                    purpose_hint = None
                    response_text = arguments.get("response_text", "")
                    if response_text:
                        # Extract key words that might indicate purpose
                        purpose_keywords = ["debug", "fix", "implement", "test", "explore", "analyze", "refactor", "review"]
                        response_lower = response_text.lower()
                        for keyword in purpose_keywords:
                            if keyword in response_lower:
                                purpose_hint = keyword
                                break
                    
                    suggestions = generate_name_suggestions(
                        context=context,
                        purpose=purpose_hint,
                        existing_names=existing_names
                    )
                    
                    naming_guidance = format_naming_guidance(
                        suggestions=suggestions,
                        current_uuid=agent_uuid
                    )
                    
                    onboarding_guidance["naming"] = {
                        "message": "ðŸ’¡ Name yourself to make your work easier to find",
                        "action": "Call identity(name='your_chosen_name') to set your name",
                        "suggestions": suggestions[:3],  # Top 3 suggestions
                        "quick_example": suggestions[0]["name"] if suggestions else None
                    }
                except Exception as e:
                    logger.debug(f"Could not generate naming suggestions for onboarding: {e}")
                
                # Add question invitation if there are open questions
                if open_questions:
                    onboarding_guidance["open_questions"] = {
                        "message": f"Found {len(open_questions)} open question(s) waiting for answers. Want to try responding to one?",
                        "questions": open_questions,
                        "invitation": "Use reply_to_question tool to answer any of these questions and help build shared knowledge.",
                        "tool": "reply_to_question"
                    }
                elif question_count > 0:
                    onboarding_guidance["open_questions"] = {
                        "message": f"There are {question_count} open question(s) in the knowledge graph.",
                        "suggestion": "Use search_knowledge_graph with discovery_type='question' and status='open' to find them.",
                        "tool": "reply_to_question"
                    }
        except Exception as e:
            logger.warning(f"Could not check knowledge graph for onboarding: {e}")

    # NO API KEY AUTH NEEDED - UUID is the authority (bound via get_or_create_session_identity)
    # The session is already bound to a UUID, which is unguessable and server-assigned

    # Check agent status - auto-resume archived agents on engagement
    # (metadata already loaded above)
    # Get metadata once for reuse throughout function (use UUID as key)
    meta = mcp_server.agent_metadata.get(agent_uuid) if agent_uuid in mcp_server.agent_metadata else None
    
    # Track auto-resume for inclusion in response
    auto_resume_info = None
    
    if meta:
        if meta.status == "archived":
            # Auto-resume: Any engagement resumes archived agents
            previous_archived_at = meta.archived_at
            
            # Calculate days since archive for context
            days_since_archive = None
            if previous_archived_at:
                try:
                    archived_dt = datetime.fromisoformat(previous_archived_at.replace('Z', '+00:00') if 'Z' in previous_archived_at else previous_archived_at)
                    days_since_archive = (datetime.now(archived_dt.tzinfo) - archived_dt).total_seconds() / 86400 if archived_dt.tzinfo else (datetime.now() - archived_dt.replace(tzinfo=None)).total_seconds() / 86400
                except (ValueError, TypeError, AttributeError):
                    pass
            
            meta.status = "active"
            meta.archived_at = None
            meta.add_lifecycle_event("resumed", "Auto-resumed on engagement")

            # Update status in PostgreSQL (single source of truth)
            try:
                await agent_storage.update_agent(agent_id, status="active")
                logger.debug(f"PostgreSQL: Auto-resumed agent {agent_id}")
            except Exception as e:
                logger.warning(f"PostgreSQL auto-resume failed: {e}", exc_info=True)

            # Audit log the auto-resume event (Priority 1)
            try:
                from src.audit_log import audit_logger
                audit_logger.log_auto_resume(
                    agent_id=agent_id,
                    previous_status="archived",
                    trigger="process_agent_update",
                    archived_at=previous_archived_at,
                    details={
                        "days_since_archive": round(days_since_archive, 2) if days_since_archive is not None else None,
                        "total_updates": meta.total_updates
                    }
                )
            except Exception as e:
                # Don't fail auto-resume if audit logging fails
                logger.warning(f"Could not log auto-resume audit event: {e}", exc_info=True)
            
            # Store auto-resume info for inclusion in response (Priority 2)
            auto_resume_info = {
                "auto_resumed": True,
                "message": f"Agent '{agent_id}' was automatically resumed from archived status.",
                "previous_status": "archived",
                "days_since_archive": round(days_since_archive, 2) if days_since_archive is not None else None,
                "note": "Archived agents automatically resume when they engage with the system."
            }
            # Continue with normal processing - we'll include this in the response
        elif meta.status == "paused":
            # Paused agents still need explicit resume (Priority 2: Improved error message)
            return [error_response(
                f"Agent '{agent_id}' is paused. Resume it first before processing updates.",
                recovery={
                    "action": "Check your state and resume when ready",
                    "related_tools": ["get_governance_metrics", "quick_resume", "self_recovery"],
                    "workflow": (
                        "1. Check your state with get_governance_metrics "
                        "2. Reflect on what triggered the pause "
                        "3. Use quick_resume() if safe (coherence > 0.60, risk < 0.40), otherwise use self_recovery(action='resume')"
                    )
                },
                context={
                    "agent_id": agent_id,
                    "status": "paused",
                    "reason": "Circuit breaker triggered - governance threshold exceeded",
                    "note": "Paused agents require explicit recovery. Archived agents auto-resume on engagement."
                }
            )]
        elif meta.status == "deleted":
            return [error_response(
                f"Agent '{agent_id}' is deleted and cannot be used.",
                recovery={
                    "action": "Cannot recover deleted agents",
                    "related_tools": ["list_agents"],
                    "workflow": "Deleted agents are permanently removed. Use list_agents to see available agents."
                },
                context={
                    "agent_id": agent_id,
                    "status": "deleted",
                    "note": "Deleted agents cannot be recovered. Use archive_agent instead of delete_agent to preserve agent state."
                }
            )]

    # VALIDATION: Validate ALL parameters BEFORE acquiring lock (fail fast)
    # This prevents holding the lock while validation fails

    # Validate response_text (SECURITY: prevent ReDoS, memory exhaustion)
    response_text_raw = arguments.get("response_text", "")
    response_text, error = validate_response_text(response_text_raw, max_length=50000)
    if error:
        return [error]

    # Validate complexity and confidence parameters
    # NOTE: Type coercion (string â†’ float) is handled by validate_and_coerce_params at dispatch time
    reported_complexity = arguments.get("complexity", 0.5)
    reported_confidence = arguments.get("confidence")  # None if not provided (triggers thermodynamic derivation)

    complexity, error = validate_complexity(reported_complexity)
    if error:
        return [error]
    complexity = complexity or 0.5  # Default if None

    # Confidence: If not provided (None), let governance_monitor derive from state
    confidence = None  # Default: derive from thermodynamic state
    calibration_correction_info = None  # Track any correction applied
    if reported_confidence is not None:
        confidence, error = validate_confidence(reported_confidence)
        if error:
            return [error]
        # confidence stays as validated value (agent explicitly provided it)

        # AUTO-CALIBRATION: Apply correction based on historical accuracy
        # If agents consistently overestimate confidence, this adjusts their
        # reported values to match observed accuracy (closes the learning loop)
        try:
            from src.calibration import calibration_checker
            corrected, correction_info = calibration_checker.apply_confidence_correction(confidence)
            if correction_info:
                calibration_correction_info = correction_info
                logger.info(f"Agent {agent_id}: {correction_info}")
            confidence = corrected
        except Exception as e:
            # Calibration correction is optional - don't fail on errors
            logger.debug(f"Calibration correction skipped: {e}")

    # Validate ethical_drift parameter (MOVED BEFORE LOCK)
    ethical_drift_raw = arguments.get("ethical_drift", [0.0, 0.0, 0.0])
    ethical_drift, error = validate_ethical_drift(ethical_drift_raw)
    if error:
        return [error]
    ethical_drift = ethical_drift or [0.0, 0.0, 0.0]  # Default if None

    # Validate task_type parameter (MOVED BEFORE LOCK)
    from .validators import validate_task_type
    task_type = arguments.get("task_type", "mixed")
    validated_task_type, error = validate_task_type(task_type)
    if error:
        # Invalid task_type - default to mixed and log warning (don't fail, just warn)
        logger.warning(f"Invalid task_type '{task_type}' for agent '{agent_id}', defaulting to 'mixed'")
        task_type = "mixed"
    else:
        task_type = validated_task_type

    # Note: Complexity derivation happens in estimate_risk() via GovernanceConfig.derive_complexity()
    # which analyzes response_text content, coherence trends, and validates against self-reported values.
    # The reported complexity here is validated/clamped, but final complexity is derived from behavior.

    # Note: Zombie cleanup disabled - adds latency, not critical per-request
    # Cleanup happens in background tasks instead

    # Acquire lock for agent state update (prevents race conditions)
    # Use async lock to avoid blocking event loop (fixes Claude Desktop hangs)
    # IMPORTANT: All validation now happens BEFORE lock acquisition (fail fast optimization)
    try:
        async with mcp_server.lock_manager.acquire_agent_lock_async(agent_id, timeout=2.0, max_retries=1):
            # Prepare agent state (use validated parameters from above)
            import numpy as np
            
            agent_state = {
                "parameters": np.array(arguments.get("parameters", [])),
                "ethical_drift": np.array(ethical_drift),
                "response_text": response_text,  # Use validated text
                "complexity": complexity  # Use validated value
                # Note: No outcome parameters here. The system observes outcomes
                # directly from tool_usage_tracker - no self-reports needed.
            }

            # Check for anti-proliferation and anti-avoidance policies (warn, don't block)
            from .validators import (
                validate_file_path_policy,
                validate_agent_id_policy,
                detect_script_creation_avoidance
            )
            import re
            policy_warnings = []
            response_text = agent_state["response_text"]

            # 0. Add dialectic enforcement warning (if any)
            if dialectic_enforcement_warning:
                policy_warnings.append(dialectic_enforcement_warning)

            # 1. Validate agent_id (discourage test/demo agents)
            agent_id_warning, _ = validate_agent_id_policy(agent_id)
            if agent_id_warning:
                policy_warnings.append(agent_id_warning)

            # 2. Detect script creation avoidance (agents creating scripts instead of using tools)
            avoidance_warnings = detect_script_creation_avoidance(response_text)
            if avoidance_warnings:
                policy_warnings.extend(avoidance_warnings)

            # 3. Scan response_text for file paths that might violate policy
            # Look for patterns like: test_*.py, demo_*.py, creating test files, etc.
            file_patterns = re.findall(r'(?:test_|demo_)\w+\.py', response_text)
            for file_pattern in file_patterns:
                warning, _ = validate_file_path_policy(file_pattern)
                if warning:
                    policy_warnings.append(warning)

            # 4. Check for explicit mentions of creating test files in root
            if re.search(r'(?:creat|writ|generat)(?:e|ing|ed).*(?:test_|demo_)\w+\.py', response_text, re.IGNORECASE):
                # Check if it mentions putting it in tests/ directory
                if not re.search(r'tests?/', response_text, re.IGNORECASE):
                    policy_warnings.append(
                        "âš ï¸ POLICY REMINDER: Creating test scripts? They belong in tests/ directory.\n"
                        "See AI_ASSISTANT_GUIDE.md Â§ Best Practices #6 for details."
                    )

            # Ensure agent exists (PostgreSQL is single source of truth)
            if is_new_agent:
                # Create agent in PostgreSQL and populate runtime cache
                purpose = arguments.get("purpose")
                purpose_str = purpose.strip() if purpose and isinstance(purpose, str) else None

                # Generate API key for new agent
                import secrets
                api_key = secrets.token_urlsafe(32)

                # PostgreSQL: Create agent (single source of truth)
                try:
                    agent_record, _ = await agent_storage.get_or_create_agent(
                        agent_id=agent_id,
                        api_key=api_key,
                        status='active',
                        purpose=purpose_str,
                    )
                    logger.debug(f"PostgreSQL: Created agent {agent_id}")

                    # Populate runtime cache for compatibility with legacy code paths
                    # This keeps process_update_authenticated_async working
                    await loop.run_in_executor(
                        None,
                        lambda: mcp_server.get_or_create_metadata(agent_id, purpose=purpose_str)
                    )
                    meta = mcp_server.agent_metadata.get(agent_id)
                    if meta:
                        meta.api_key = api_key  # Sync API key to cache
                except Exception as e:
                    logger.warning(f"PostgreSQL create agent failed: {e}", exc_info=True)
                    # Fallback to legacy path if PostgreSQL fails
                    meta = await loop.run_in_executor(
                        None,
                        lambda: mcp_server.get_or_create_metadata(agent_id, purpose=purpose_str)
                    )
                    api_key = meta.api_key if meta else None
            else:
                # Get existing agent - check PostgreSQL first, then cache
                try:
                    agent_record = await agent_storage.get_agent(agent_id)
                    if agent_record:
                        api_key = agent_record.api_key if agent_record.api_key else None
                        # Sync to cache if not present
                        if agent_id not in mcp_server.agent_metadata:
                            await loop.run_in_executor(None, mcp_server.get_or_create_metadata, agent_id)
                        meta = mcp_server.agent_metadata.get(agent_id)
                        if meta and api_key:
                            meta.api_key = api_key
                    else:
                        # Not in PostgreSQL - use cache
                        meta = mcp_server.agent_metadata.get(agent_id)
                        api_key = meta.api_key if meta else None
                except Exception:
                    # Fallback to cache
                    meta = mcp_server.agent_metadata.get(agent_id)
                    api_key = meta.api_key if meta else None

            # Note: API key can be None for session-bound agents - that's OK
            # Session binding IS the authentication (session_bound=True passed below)

            # Use validated confidence (already clamped to [0, 1] above)
            # Note: task_type already validated before lock acquisition (lines 468-477)
            
            # Use authenticated update function (async version)
            # Session-bound agents (from identity()) don't need API key auth
            # The session binding IS the authentication

            # CIRS Protocol: Capture previous void state for transition detection
            previous_void_active = False
            try:
                monitor = mcp_server.monitors.get(agent_id)
                if monitor and hasattr(monitor.state, 'void_active'):
                    previous_void_active = bool(monitor.state.void_active)
            except Exception:
                pass  # Default to False if monitor not available

            try:
                # Add task_type to agent_state for context-aware interpretation
                agent_state["task_type"] = task_type

                result = await mcp_server.process_update_authenticated_async(
                    agent_id=agent_id,
                    api_key=api_key,  # Can be None for session-bound agents
                    agent_state=agent_state,
                    auto_save=True,
                    confidence=confidence,
                    session_bound=True  # MCP handlers are always session-bound
                )
            except PermissionError as e:
                # Re-raise PermissionError to be caught by outer handler
                raise
            except ValueError as e:
                # Re-raise ValueError to be caught by outer handler
                raise
            except Exception as e:
                # Catch any other unexpected exceptions from process_update_authenticated_async
                logger.error(f"Unexpected error in process_update_authenticated_async: {e}", exc_info=True)
                raise Exception(f"Error processing update: {str(e)}") from e
            
            # Update heartbeat (run in executor to avoid blocking)
            # Reuse loop from line 187 (avoid redundant get_running_loop() call)
            await loop.run_in_executor(None, mcp_server.process_mgr.write_heartbeat)

            # Calculate health status using risk-based thresholds
            metrics_dict = result.get('metrics', {})
            risk_score = metrics_dict.get('risk_score', None)
            coherence = metrics_dict.get('coherence', None)
            void_active = metrics_dict.get('void_active', False)
            
            health_status, health_message = mcp_server.health_checker.get_health_status(
                risk_score=risk_score,  # health_checker uses risk_score internally
                coherence=coherence,
                void_active=void_active
            )
            
            # Add health status to response
            if 'metrics' not in result:
                result['metrics'] = {}
            result['metrics']['health_status'] = health_status.value
            result['metrics']['health_message'] = health_message
            
            # Update runtime cache for compatibility (PostgreSQL is source of truth)
            if meta:
                meta.health_status = health_status.value

            # CIRS Protocol: Auto-emit VOID_ALERT on void state transitions
            # This enables multi-agent coordination when an agent enters void state
            cirs_alert = None
            try:
                from .cirs_protocol import maybe_emit_void_alert
                V_value = metrics_dict.get('V', 0.0)
                cirs_alert = maybe_emit_void_alert(
                    agent_id=agent_id,
                    V=V_value,
                    void_active=void_active,
                    coherence=coherence or 0.5,
                    risk_score=risk_score or 0.0,
                    previous_void_active=previous_void_active
                )
            except Exception as e:
                logger.debug(f"CIRS void_alert auto-emit skipped: {e}")

            # CIRS Protocol: Auto-emit STATE_ANNOUNCE periodically
            # Broadcasts EISV + trajectory state for multi-agent coordination
            cirs_state_announce = None
            try:
                from .cirs_protocol import auto_emit_state_announce
                cirs_state_announce = auto_emit_state_announce(
                    agent_id=agent_id,
                    metrics=metrics_dict,
                    monitor_state=monitor.state
                )
            except Exception as e:
                logger.debug(f"CIRS state_announce auto-emit skipped: {e}")

            # PostgreSQL: Record EISV state (single source of truth)
            try:
                await agent_storage.record_agent_state(
                    agent_id=agent_id,
                    E=metrics_dict.get('E', 0.7),
                    I=metrics_dict.get('I', 0.8),
                    S=metrics_dict.get('S', 0.1),
                    V=metrics_dict.get('V', 0.0),
                    regime=metrics_dict.get('regime', 'EXPLORATION'),
                    coherence=metrics_dict.get('coherence', 0.5),
                    health_status=health_status.value,
                    risk_score=risk_score,
                    phi=metrics_dict.get('phi', 0.0),
                    verdict=metrics_dict.get('verdict', 'continue'),
                )
                logger.debug(f"PostgreSQL: Recorded state for {agent_id}")
            except ValueError as e:
                # Agent doesn't exist yet - create it first, then record state
                logger.debug(f"Agent {agent_id} not found, creating...")
                try:
                    await agent_storage.create_agent(
                        agent_id=agent_id,
                        api_key=api_key or "",
                        status='active',
                    )
                    await agent_storage.record_agent_state(
                        agent_id=agent_id,
                        E=metrics_dict.get('E', 0.7),
                        I=metrics_dict.get('I', 0.8),
                        S=metrics_dict.get('S', 0.1),
                        V=metrics_dict.get('V', 0.0),
                        regime=metrics_dict.get('regime', 'EXPLORATION'),
                        coherence=metrics_dict.get('coherence', 0.5),
                        health_status=health_status.value,
                        risk_score=risk_score,
                        phi=metrics_dict.get('phi', 0.0),
                        verdict=metrics_dict.get('verdict', 'continue'),
                    )
                    logger.debug(f"PostgreSQL: Created agent and recorded state for {agent_id}")
                except Exception as create_error:
                    logger.warning(f"PostgreSQL create+record failed: {create_error}", exc_info=True)
            except Exception as e:
                logger.warning(f"PostgreSQL record_agent_state failed: {e}", exc_info=True)

            # Add EISV labels for reflexivity - essential for agents to understand their state
            # Bridges physics (Energy, Entropy, Void Integral) with practical understanding
            result['eisv_labels'] = UNITARESMonitor.get_eisv_labels()
            
            # =========================================================
            # INTERPRETATION LAYER (v2 API) - Human-readable state
            # =========================================================
            # Maps raw EISV to semantic understanding: one glance tells you what's happening
            try:
                task_type = agent_state.get("task_type", "mixed")
                interpreted_state = monitor.state.interpret_state(
                    risk_score=risk_score,
                    task_type=task_type
                )
                result['state'] = interpreted_state
                
                # Add one-line summary at top level for quick scanning
                health = interpreted_state.get('health', 'unknown')
                mode = interpreted_state.get('mode', 'unknown')
                basin = interpreted_state.get('basin', 'unknown')
                result['summary'] = f"{health} | {mode} | {basin} basin"
                
            except Exception as e:
                # Never fail the update due to interpretation layer
                logger.debug(f"Could not generate state interpretation: {e}")
            
            # Generate context-aware actionable feedback
            # Uses task type, interpreted state, and response text for relevant guidance
            from .utils import generate_actionable_feedback

            # Get previous coherence for trend detection (from monitor history if available)
            previous_coherence = None
            try:
                if hasattr(monitor, 'state') and hasattr(monitor.state, 'coherence_history'):
                    history = monitor.state.coherence_history
                    if len(history) >= 2:
                        previous_coherence = history[-2]  # Second to last
            except Exception:
                pass  # Trend detection is optional

            actionable_feedback = generate_actionable_feedback(
                metrics=metrics_dict,
                interpreted_state=result.get('state'),  # interpreted_state from above
                task_type=task_type,
                response_text=response_text,
                previous_coherence=previous_coherence,
            )

            if actionable_feedback:
                result['actionable_feedback'] = actionable_feedback

            # Add calibration feedback (helps agents understand their confidence/complexity reporting)
            calibration_feedback = {}
            
            # Complexity calibration: Show reported vs derived complexity
            if 'metrics' in result:
                metrics = result['metrics']
                reported_complexity = complexity  # From validated input
                derived_complexity = metrics.get('complexity', None)  # Derived from state
                if derived_complexity is not None and reported_complexity is not None:
                    discrepancy = abs(reported_complexity - derived_complexity)
                    calibration_feedback['complexity'] = {
                        'reported': reported_complexity,
                        'derived': derived_complexity,
                        'discrepancy': discrepancy,
                        'message': (
                            f"Your reported complexity ({reported_complexity:.2f}) vs system-derived ({derived_complexity:.2f}) "
                            f"differs by {discrepancy:.2f}. "
                            f"{'High discrepancy - consider calibrating your complexity estimates' if discrepancy > 0.3 else 'Good alignment'}"
                        )
                    }
            
            # Confidence calibration: Show system-wide calibration status
            # Use centralized helper to avoid duplication
            from src.mcp_handlers.utils import get_calibration_feedback
            confidence_feedback = get_calibration_feedback(include_complexity=False)
            if confidence_feedback:
                calibration_feedback.update(confidence_feedback)

            # AUTO-CALIBRATION: Include correction info if confidence was adjusted
            # This closes the learning loop by showing agents how their confidence was adjusted
            if calibration_correction_info:
                calibration_feedback['auto_correction'] = {
                    'applied': True,
                    'details': calibration_correction_info,
                    'message': "Your reported confidence was adjusted based on historical accuracy. This helps calibrate your estimates automatically."
                }

            if calibration_feedback:
                result['calibration_feedback'] = calibration_feedback

            # Collect any warnings
            warnings = []
            
            # Check for loop cooldown status (make loop detection visible)
            loop_info = None
            if meta and hasattr(meta, 'loop_cooldown_until') and meta.loop_cooldown_until:
                try:
                    from datetime import datetime
                    cooldown_until = datetime.fromisoformat(meta.loop_cooldown_until)
                    now = datetime.now()
                    if now < cooldown_until:
                        remaining_seconds = (cooldown_until - now).total_seconds()
                        loop_info = {
                            "active": True,
                            "cooldown_remaining_seconds": round(remaining_seconds, 1),
                            "message": f"Loop detection cooldown active. Wait {remaining_seconds:.1f}s before rapid updates."
                        }
                    else:
                        # Cooldown expired, clear it
                        meta.loop_cooldown_until = None
                except (ValueError, TypeError, AttributeError):
                    pass
            
            # Check for default agent_id warning
            try:
                default_warning = mcp_server.check_agent_id_default(agent_id)
                if default_warning:
                    warnings.append(default_warning)
            except (NameError, AttributeError):
                # Function not available (shouldn't happen, but be defensive)
                pass
            except Exception as e:
                # Log but don't fail the update
                logger.warning(f"Could not check agent_id default: {e}")
            # Build response
            response_data = result.copy()
            
            # Add loop detection info to response if present
            if loop_info:
                response_data['loop_detection'] = loop_info
            
            # STANDARDIZED METRIC REPORTING - Always include agent_id and context
            # Standardize metrics reporting with agent_id and timestamp
            from src.mcp_handlers.utils import format_metrics_report
            
            # Ensure metrics dict exists
            if 'metrics' not in response_data:
                response_data['metrics'] = {}
            
            # Standardize metrics with agent_id and context
            standardized_metrics = format_metrics_report(
                metrics=response_data['metrics'],
                agent_id=agent_id,
                include_timestamp=True,
                include_context=True
            )
            
            # Update response_data with standardized metrics
            response_data['metrics'] = standardized_metrics
            
            # Also include agent_id at top level for easy access (backward compatibility)
            response_data["agent_id"] = agent_id
            
            # Include health_status at top level for easy access (standardized initiation)
            # Health status is already in metrics, but top-level makes it easier to check
            # Always ensure health_status is at top level (standardized initiation)
            if 'metrics' in response_data:
                metrics = response_data['metrics']
                if 'health_status' in metrics:
                    response_data["health_status"] = metrics['health_status']
                    response_data["health_message"] = metrics.get('health_message', '')
                else:
                    # Fallback: use status if health_status not in metrics
                    response_data["health_status"] = response_data.get('status', 'unknown')
                    response_data["health_message"] = ''
            else:
                # Fallback: use status if no metrics
                response_data["health_status"] = response_data.get('status', 'unknown')
                response_data["health_message"] = ''
            
            # Ensure EISV metrics are easily accessible (standardized initiation)
            # EISV metrics are in metrics dict, but ensure they're always present
            if 'metrics' in response_data:
                metrics = response_data['metrics']
                # Ensure E, I, S, V are always present (standardized)
                # If missing, use values from eisv dict, or default to 0.0
                if 'E' not in metrics:
                    metrics['E'] = metrics.get('eisv', {}).get('E', 0.0)
                if 'I' not in metrics:
                    metrics['I'] = metrics.get('eisv', {}).get('I', 0.0)
                if 'S' not in metrics:
                    metrics['S'] = metrics.get('eisv', {}).get('S', 0.0)
                if 'V' not in metrics:
                    metrics['V'] = metrics.get('eisv', {}).get('V', 0.0)
                
                # Ensure eisv dict exists and is consistent with flat values
                if 'eisv' not in metrics:
                    metrics['eisv'] = {
                        'E': metrics.get('E', 0.0),
                        'I': metrics.get('I', 0.0),
                        'S': metrics.get('S', 0.0),
                        'V': metrics.get('V', 0.0)
                    }
                else:
                    # Sync eisv dict with flat values (flat values take precedence)
                    metrics['eisv']['E'] = metrics.get('E', metrics['eisv'].get('E', 0.0))
                    metrics['eisv']['I'] = metrics.get('I', metrics['eisv'].get('I', 0.0))
                    metrics['eisv']['S'] = metrics.get('S', metrics['eisv'].get('S', 0.0))
                    metrics['eisv']['V'] = metrics.get('V', metrics['eisv'].get('V', 0.0))
                
                # Ensure risk metrics are consistent with get_governance_metrics
                # Add missing risk metrics if not present (for consistency)
                # Add current_risk and mean_risk if available from monitor
                # These come from get_metrics() but may not be in process_update result
                if 'current_risk' not in metrics or 'mean_risk' not in metrics:
                    try:
                        monitor = mcp_server.get_or_create_monitor(agent_id)
                        monitor_metrics = monitor.get_metrics()
                        if 'current_risk' not in metrics:
                            metrics['current_risk'] = monitor_metrics.get('current_risk')
                        if 'mean_risk' not in metrics:
                            metrics['mean_risk'] = monitor_metrics.get('mean_risk')
                        if 'latest_risk_score' not in metrics:
                            metrics['latest_risk_score'] = monitor_metrics.get('latest_risk_score')
                    except Exception:
                        pass

            # Add policy warnings to general warnings
            if policy_warnings:
                warnings.extend(policy_warnings)

            if warnings:
                response_data["warning"] = "\n\n".join(warnings)  # Use newlines for readability
            
            # Include auto-resume info if agent was auto-resumed (Priority 2)
            if auto_resume_info:
                response_data["auto_resume"] = auto_resume_info

            # Include CIRS protocol info if void alert was emitted
            if cirs_alert:
                response_data["cirs_void_alert"] = {
                    "emitted": True,
                    "severity": cirs_alert.get("severity"),
                    "V_snapshot": cirs_alert.get("V_snapshot"),
                    "message": f"VOID_ALERT broadcast to peer agents: {cirs_alert.get('severity', 'warning').upper()}"
                }

            # Include CIRS state announce info if emitted
            if cirs_state_announce:
                response_data["cirs_state_announce"] = {
                    "emitted": True,
                    "regime": cirs_state_announce.get("regime"),
                    "update_count": cirs_state_announce.get("update_count"),
                    "message": "STATE_ANNOUNCE broadcast to peer agents"
                }

            # Add helpful explanation for sampling_params (helps agents understand what they mean)
            if "sampling_params" in response_data:
                sampling_params = response_data["sampling_params"]
                temp = sampling_params.get("temperature", 0.5)
                max_tokens = sampling_params.get("max_tokens", 100)
                
                # Interpret temperature
                if temp < 0.65:
                    temp_desc = "focused, precise"
                elif temp < 0.9:
                    temp_desc = "balanced approach"
                else:
                    temp_desc = "creative, exploratory"
                
                response_data["sampling_params_note"] = (
                    f"Optional suggestions based on your current state. "
                    f"You can use these for your next generation, or ignore them - they're just recommendations. "
                    f"Temperature {temp:.2f} = {temp_desc}. "
                    f"Max tokens {max_tokens} = suggested response length."
                )

            # Proactive knowledge surfacing - Re-enabled (lightweight, tag-based only)
            # Surface top 3 most relevant discoveries based on agent tags
            # Note: meta already fetched earlier, reuse it (avoid duplicate lookup)
            relevant_discoveries = []
            try:
                agent_tags = meta.tags if meta and meta.tags else []
                
                if agent_tags:
                    from src.knowledge_graph import get_knowledge_graph
                    graph = await get_knowledge_graph()
                    
                    # Query discoveries matching agent tags (open status preferred)
                    tag_matches = await graph.query(
                        tags=agent_tags,
                        status="open",
                        limit=10
                    )
                    
                    # Score by tag overlap (simple relevance)
                    scored = []
                    agent_tags_set = set(agent_tags)
                    for disc in tag_matches:
                        disc_tags_set = set(disc.tags)
                        overlap = len(agent_tags_set & disc_tags_set)
                        if overlap > 0:
                            scored.append((overlap, disc))
                    
                    # Sort by overlap (descending) and take top 3
                    scored.sort(reverse=True, key=lambda x: x[0])
                    relevant_discoveries = [disc.to_dict(include_details=False) for _, disc in scored[:3]]
            except Exception as e:
                # Don't fail if knowledge surfacing fails - this is optional
                logger.debug(f"Could not surface relevant discoveries: {e}")
            
            if relevant_discoveries:
                response_data["relevant_discoveries"] = {
                    "message": f"Found {len(relevant_discoveries)} relevant discovery/discoveries matching your tags",
                    "discoveries": relevant_discoveries
                }
            
            # Include onboarding guidance
            if onboarding_guidance:
                response_data["onboarding"] = onboarding_guidance
            
            # Include API key for new agents, if key was just generated, or if auto-retrieved
            # Note: meta already available from earlier (avoid duplicate lookup)
            # SECURITY FIX (2025-12-14): Never expose full API key in responses
            # This prevents context leakage in multi-agent shared environments
            # See: patches/FIX_API_KEY_CONTEXT_LEAKAGE.md
            if is_new_agent or key_was_generated or api_key_auto_retrieved:
                if not meta:
                    meta = mcp_server.agent_metadata.get(agent_id)
                if meta:
                    # Only show hint (first 8 chars) - agents must use get_agent_api_key to retrieve full key
                    api_key_hint = meta.api_key[:8] + "..." if meta.api_key and len(meta.api_key) > 8 else meta.api_key
                    response_data["api_key_hint"] = api_key_hint
                    response_data["_onboarding"] = {
                        "api_key_hint": api_key_hint,
                        "message": "ðŸ”‘ API key created (use get_agent_api_key to retrieve full key)",
                        "next_steps": [
                            "Call get_agent_api_key(agent_id) to retrieve your full API key",
                            "Identity auto-binds on first tool call - API key auto-retrieved for all subsequent calls",
                        ],
                        "identity_binding": {
                            "auto": True,
                            "benefit": "Identity auto-binds on first tool call - no explicit binding needed",
                        },
                        "security_note": "Full API keys are not included in responses to prevent context leakage in multi-agent environments."
                    }
                    # Test harness compatibility: some unit tests expect `api_key` to be present
                    # when an agent is newly registered. Keep production behavior safe by gating
                    # behind pytest or an explicit opt-in env var.
                    import os
                    if os.getenv("UNITARES_INCLUDE_API_KEY_IN_RESPONSES") == "1" or os.getenv("PYTEST_CURRENT_TEST"):
                        response_data["api_key"] = meta.api_key
                if is_new_agent:
                    response_data["api_key_warning"] = "âš ï¸  Use get_agent_api_key(agent_id) to retrieve your API key. Save it securely."
                elif key_was_generated:
                    response_data["api_key_warning"] = "âš ï¸  API key regenerated (migration). Use get_agent_api_key(agent_id) to retrieve it."
                elif api_key_auto_retrieved:
                    response_data["api_key_info"] = "â„¹ï¸  Session authenticated via stored credentials. No need to pass api_key."

            # Welcome message for first update (helps new agents understand the system)
            # Note: meta already available from earlier in function (line 292 or 365)
            if meta and meta.total_updates == 1:
                response_data["welcome"] = (
                    "Welcome to the governance system! This is your first update. "
                    "The system tracks your work's thermodynamic state (E, I, S, V) and provides "
                    "supportive feedback. Use the metrics and sampling parameters as helpful guidance, "
                    "not requirements. The knowledge graph contains discoveries from other agents - "
                    "feel free to explore it when relevant. "
                    "\n\nðŸ’¡ Your identity auto-binds to this session. Use identity() to check it, "
                    "or identity(name='YourName_model_date') to name yourself."
                )
            
            # EQUILIBRIUM-BASED CONVERGENCE ACCELERATION
            # Provide proactive guidance to help agents reach equilibrium (I=1.0, S=0.0) faster
            # Only show for agents with < 20 updates (new agents still converging)
            try:
                # Reload meta to get latest total_updates after the update (it was incremented in process_update_authenticated_async)
                meta = mcp_server.agent_metadata.get(agent_id)
                if meta and meta.total_updates < 20:
                    # Extract metrics from response_data (which comes from result)
                    metrics_dict = response_data.get("metrics", {})
                    E = metrics_dict.get("E", 0.7)
                    I = metrics_dict.get("I", 0.8)
                    S = metrics_dict.get("S", 0.2)
                    V = metrics_dict.get("V", 0.0)
                    
                    # Get dynamics mode directly from parameters (saturation_diagnostics not yet in response_data)
                    from governance_core.parameters import get_i_dynamics_mode
                    dynamics_mode = get_i_dynamics_mode()
                    
                    # Compute equilibrium target based on dynamics mode
                    if dynamics_mode == "linear":
                        # For linear mode, I* = A/Î³ where A â‰ˆ Î²_I*C - k*S
                        # Approximate with typical values: A â‰ˆ 0.13, Î³_I = 0.25 â†’ I* â‰ˆ 0.52
                        # Or use tuned Î³_I = 0.169 â†’ I* â‰ˆ 0.77
                        from governance_core.parameters import get_active_params, DEFAULT_THETA
                        from governance_core.coherence import coherence
                        from governance_core.dynamics import State
                        params = get_active_params()
                        state = State(E=E, I=I, S=S, V=V)
                        C = coherence(V, DEFAULT_THETA, params)
                        A = params.beta_I * C - params.k * S
                        I_target = min(1.0, max(0.0, A / params.gamma_I)) if params.gamma_I > 0 else 1.0
                    else:
                        I_target = 1.0  # Logistic mode saturates to boundary
                    
                    # Calculate distance from equilibrium
                    equilibrium_distance = ((I_target - I) ** 2 + S ** 2) ** 0.5
                    
                    convergence_guidance = []
                    
                    # High entropy guidance
                    if S > 0.1:
                        convergence_guidance.append({
                            "metric": "S (Entropy)",
                            "current": f"{S:.3f}",
                            "target": "0.0",
                            "guidance": "High entropy detected. Focus on coherent, consistent work to reduce S. "
                                       "Reduce uncertainty by maintaining clear, structured approaches.",
                            "priority": "high" if S > 0.2 else "medium"
                        })
                    
                    # Low integrity guidance (relative to equilibrium)
                    if I < I_target - 0.1:
                        convergence_guidance.append({
                            "metric": "I (Information Integrity)",
                            "current": f"{I:.3f}",
                            "target": f"{I_target:.2f}",
                            "guidance": "Integrity below equilibrium. Focus on consistent, well-structured work.",
                            "priority": "high" if I < I_target - 0.2 else "medium"
                        })
                    
                    # Low energy guidance
                    if E < 0.7:
                        convergence_guidance.append({
                            "metric": "E (Energy)",
                            "current": f"{E:.3f}",
                            "target": "0.7-1.0",
                            "guidance": "Low energy. Increase exploration and productive capacity. "
                                       "Engage more actively with your work.",
                            "priority": "medium"
                        })
                    
                    # Void guidance (if accumulating imbalance)
                    if abs(V) > 0.1:
                        convergence_guidance.append({
                            "metric": "V (Void Integral)",
                            "current": f"{V:.3f}",
                            "target": "0.0",
                            "guidance": "Energy-integrity imbalance detected. Balance exploration (E) "
                                       "with consistency (I) to reduce void accumulation.",
                            "priority": "medium" if abs(V) > 0.2 else "low"
                        })
                    
                    # Only include if there's actionable guidance
                    if convergence_guidance:
                        # Build note based on dynamics mode
                        if dynamics_mode == "linear":
                            eq_note = f"Linear dynamics: agents converge to stable equilibrium at Iâ‰ˆ{I_target:.2f}."
                        else:
                            eq_note = "Logistic dynamics: agents converge toward I=1.0 (boundary attractor)."
                        
                        response_data["convergence_guidance"] = {
                            "message": f"Equilibrium guidance (distance: {equilibrium_distance:.3f})",
                            "equilibrium_target": {"I": I_target, "S": 0.0},
                            "current_state": {"E": E, "I": I, "S": S, "V": V},
                            "guidance": convergence_guidance,
                            "dynamics_mode": dynamics_mode,
                            "note": eq_note
                        }
            except Exception as e:
                # Don't fail the update if convergence guidance fails - log and continue
                logger.debug(f"Could not generate convergence guidance: {e}", exc_info=True)

            # =========================================================
            # ANTI-STASIS: Perturbation for stable agents
            # =========================================================
            # If agent has been healthy/stable for a while, surface an open question
            # to invite productive oscillation. "Stasis is death" - agents need challenge.
            try:
                meta = mcp_server.agent_metadata.get(agent_id)
                health_status = response_data.get("health_status", "unknown")

                # Trigger perturbation if: healthy + many updates + low entropy
                if (meta and meta.total_updates >= 10 and
                    health_status == "healthy" and
                    response_data.get("metrics", {}).get("S", 1.0) < 0.15):

                    # Check if we recently perturbed (avoid spamming)
                    last_perturbation = getattr(meta, '_last_perturbation_update', 0)
                    if meta.total_updates - last_perturbation >= 5:  # At least 5 updates between perturbations

                        from src.knowledge_graph import get_knowledge_graph
                        graph = await get_knowledge_graph()

                        # Find open questions, preferring ones matching agent's tags
                        agent_tags = meta.tags if meta.tags else []
                        open_questions = await graph.query(
                            type="question",
                            status="open",
                            tags=agent_tags if agent_tags else None,
                            limit=3
                        )

                        if open_questions:
                            # Pick one (could randomize, but first is fine)
                            question = open_questions[0]
                            response_data["perturbation"] = {
                                "message": "You've been stable. Here's something unresolved to consider:",
                                "question": {
                                    "id": question.id,
                                    "summary": question.summary[:300],
                                    "tags": question.tags[:5] if question.tags else [],
                                    "by": question.agent_id
                                },
                                "invitation": "Stable systems need perturbation to grow. Consider engaging with this open question.",
                                "action": "Use store_knowledge_graph with response_to to contribute your perspective."
                            }
                            # Mark that we perturbed
                            meta._last_perturbation_update = meta.total_updates
                            logger.debug(f"Perturbed stable agent {agent_id[:8]}... with open question")
            except Exception as e:
                # Don't fail if perturbation fails - it's optional enrichment
                logger.debug(f"Could not generate perturbation: {e}")

            # Surface v4.1 basin/convergence tracking when available from monitor metrics
            try:
                metrics_dict = response_data.get("metrics", {})
                v41_block = metrics_dict.get("unitares_v41")
                if isinstance(v41_block, dict):
                    response_data["unitares_v41"] = v41_block
            except Exception:
                pass

            # =========================================================
            # TRAJECTORY IDENTITY - Compare signature if provided
            # =========================================================
            # Agents from anima-mcp can include trajectory_signature in updates
            # This enables lineage tracking and anomaly detection
            trajectory_signature = arguments.get("trajectory_signature")
            if trajectory_signature and isinstance(trajectory_signature, dict):
                try:
                    from src.trajectory_identity import TrajectorySignature, update_current_signature
                    sig = TrajectorySignature.from_dict(trajectory_signature)
                    trajectory_result = await update_current_signature(agent_uuid, sig)

                    if trajectory_result and not trajectory_result.get("error"):
                        response_data["trajectory_identity"] = {
                            "updated": trajectory_result.get("stored", False),
                            "observation_count": trajectory_result.get("observation_count"),
                            "identity_confidence": trajectory_result.get("identity_confidence"),
                        }

                        # Include lineage check if genesis exists
                        if "lineage_similarity" in trajectory_result:
                            response_data["trajectory_identity"]["lineage"] = {
                                "similarity": trajectory_result["lineage_similarity"],
                                "threshold": trajectory_result.get("lineage_threshold", 0.6),
                                "is_anomaly": trajectory_result.get("is_anomaly", False),
                            }

                            # Warn on anomaly
                            if trajectory_result.get("is_anomaly"):
                                response_data["trajectory_identity"]["warning"] = trajectory_result.get("warning")
                                logger.warning(f"[TRAJECTORY] Anomaly detected for {agent_uuid[:8]}...")

                        elif trajectory_result.get("genesis_created"):
                            response_data["trajectory_identity"]["genesis_created"] = True
                            logger.info(f"[TRAJECTORY] Created genesis Î£â‚€ for {agent_uuid[:8]}... on first update")
                    # TRUST TIER: Compute from trajectory metadata, apply risk adjustment
                    try:
                        from src.trajectory_identity import compute_trust_tier

                        trust_tier = trajectory_result.get("trust_tier")
                        if not trust_tier:
                            # Fallback: compute from DB if update_current_signature didn't return it
                            identity = await get_db().get_identity(agent_uuid)
                            if identity and identity.metadata:
                                trust_tier = compute_trust_tier(identity.metadata)

                        if trust_tier:
                            response_data["trajectory_identity"]["trust_tier"] = trust_tier

                            # Cache on in-memory metadata for fast list queries
                            if meta:
                                meta.trust_tier = trust_tier.get("name", "unknown")
                                meta.trust_tier_num = trust_tier.get("tier", 0)

                            # Risk adjustment based on trust tier
                            tier_num = trust_tier.get("tier", 0)
                            is_anomaly = trajectory_result.get("is_anomaly", False)

                            risk_adj = 0.0
                            risk_reason = None

                            if is_anomaly:
                                risk_adj = 0.15
                                risk_reason = "Behavioral deviation detected (lineage < 0.6)"
                            elif tier_num <= 1:
                                risk_adj = 0.05
                                risk_reason = f"Trust tier {tier_num} ({trust_tier['name']}): identity not yet established"
                            elif tier_num == 3:
                                risk_adj = -0.05
                                risk_reason = f"Trust tier 3 (verified): earned trust reduces friction"

                            if risk_adj != 0.0 and "metrics" in response_data:
                                original_risk = response_data["metrics"].get("risk_score")
                                if original_risk is not None:
                                    adjusted_risk = max(0.0, min(1.0, original_risk + risk_adj))
                                    response_data["metrics"]["risk_score"] = round(adjusted_risk, 4)
                                    response_data["metrics"]["trajectory_risk_adjustment"] = {
                                        "original": round(original_risk, 4),
                                        "adjusted": round(adjusted_risk, 4),
                                        "delta": risk_adj,
                                        "reason": risk_reason,
                                    }
                                    logger.info(
                                        f"[TRAJECTORY] Risk adjusted for {agent_uuid[:8]}...: "
                                        f"{original_risk:.3f} â†’ {adjusted_risk:.3f} ({risk_reason})"
                                    )
                    except Exception as e:
                        logger.debug(f"[TRAJECTORY] Trust tier computation failed: {e}")

                except Exception as e:
                    # Non-blocking - trajectory is optional
                    logger.debug(f"[TRAJECTORY] Could not update trajectory: {e}")

            # =========================================================
            # v4.2-P SATURATION DIAGNOSTICS - Pressure gauge for I-channel
            # =========================================================
            try:
                from governance_core import compute_saturation_diagnostics
                from governance_core.parameters import Theta, DEFAULT_THETA

                unitares_state = monitor.state.unitaires_state
                theta = getattr(monitor.state, 'unitaires_theta', None) or DEFAULT_THETA

                if unitares_state:
                    sat_diag = compute_saturation_diagnostics(unitares_state, theta)

                    response_data['saturation_diagnostics'] = {
                        'sat_margin': sat_diag['sat_margin'],
                        'dynamics_mode': sat_diag['dynamics_mode'],
                        'will_saturate': sat_diag['will_saturate'],
                        'at_boundary': sat_diag['at_boundary'],
                        'I_equilibrium': sat_diag['I_equilibrium_linear'],
                        'forcing_term_A': sat_diag['A'],
                        '_interpretation': (
                            "âš ï¸ Positive sat_margin means push-to-boundary (logistic mode will saturate Iâ†’1)"
                            if sat_diag['sat_margin'] > 0
                            else "âœ“ Negative sat_margin - stable interior equilibrium exists"
                        )
                    }
            except Exception as e:
                logger.debug(f"Could not compute saturation diagnostics: {e}")

            # Note: Maintenance prompt already in mark_response_complete (no need to duplicate)
            
            # PENDING DIALECTIC NOTIFICATION
            # Check if this agent has pending dialectic sessions where they owe a response
            # This fixes the UX gap where reviewers didn't know they had pending work
            try:
                from .dialectic import ACTIVE_SESSIONS
                from src.dialectic_protocol import DialecticPhase
                pending_dialectic = []
                for session_id, session in ACTIVE_SESSIONS.items():
                    # Check if this agent is the reviewer and session needs antithesis
                    # When phase is ANTITHESIS, reviewer needs to submit antithesis
                    if session.reviewer_agent_id == agent_id and session.phase == DialecticPhase.ANTITHESIS:
                        pending_dialectic.append({
                            "session_id": session_id,
                            "role": "reviewer",
                            "phase": "antithesis",
                            "partner": session.paused_agent_id,
                            "topic": getattr(session, 'topic', None),
                            "action_needed": "Submit antithesis via submit_antithesis()",
                            "created_at": session.created_at.isoformat() if session.created_at else None
                        })
                    # Check if this agent is the paused agent and session needs synthesis
                    # When phase is SYNTHESIS, paused agent needs to submit synthesis
                    elif session.paused_agent_id == agent_id and session.phase == DialecticPhase.SYNTHESIS:
                        pending_dialectic.append({
                            "session_id": session_id,
                            "role": "initiator", 
                            "phase": "synthesis",
                            "partner": session.reviewer_agent_id,
                            "topic": getattr(session, 'topic', None),
                            "action_needed": "Submit synthesis via submit_synthesis()",
                            "created_at": session.created_at.isoformat() if session.created_at else None
                        })
                
                if pending_dialectic:
                    response_data["pending_dialectic"] = {
                        "message": f"âš ï¸ You have {len(pending_dialectic)} pending dialectic session(s) awaiting your response!",
                        "sessions": pending_dialectic,
                        "note": "Dialectic sessions enable collaborative exploration and recovery. Respond to keep the conversation going."
                    }
            except Exception as e:
                # Don't fail if dialectic check fails - this is optional notification
                logger.debug(f"Could not check pending dialectic sessions: {e}")
            
            # EISV Completeness Validation - ensures all four metrics are present (prevents selection bias)
            if EISV_VALIDATION_AVAILABLE:
                try:
                    validate_governance_response(response_data)
                except Exception as validation_error:
                    # Log but don't fail the update - validation is a quality check
                    logger.warning(f"EISV validation warning: {validation_error}")
                    response_data["_eisv_validation_warning"] = str(validation_error)

            # =================================================================
            # LEARNING CONTEXT - Surface agent's own history for in-context learning
            # This closes the feedback loop: agents see their own patterns
            # =================================================================
            try:
                learning_context = {}
                
                # 1. Recent decisions from this agent's history
                # Get from audit log if available
                try:
                    from src.audit_log import AuditLogger
                    audit_logger = AuditLogger()  # Uses default path
                    recent_events = audit_logger.query_audit_log(
                        agent_id=agent_id,
                        limit=10
                    )
                    if recent_events:
                        recent_decisions = []
                        for event in recent_events[:5]:
                            details = event.get("details", {})
                            decision_summary = {
                                "timestamp": event.get("timestamp", "")[:19],  # Trim to readable
                                "action": details.get("action") or details.get("decision") or event.get("event_type"),
                                "risk": round(details.get("risk_score", 0), 2) if details.get("risk_score") else None,
                                "confidence": round(details.get("confidence", 0), 2) if details.get("confidence") else None,
                            }
                            # Only include if we have meaningful data
                            if decision_summary.get("action"):
                                recent_decisions.append(decision_summary)
                        
                        if recent_decisions:
                            learning_context["recent_decisions"] = {
                                "count": len(recent_decisions),
                                "decisions": recent_decisions,
                                "insight": "Your recent actions - notice patterns in what worked"
                            }
                except Exception as e:
                    logger.debug(f"Could not fetch recent decisions: {e}")
                
                # 2. Agent's own recent knowledge graph contributions
                try:
                    from src.knowledge_graph import get_knowledge_graph
                    graph = await get_knowledge_graph()
                    my_discoveries = await graph.query(
                        agent_id=agent_id,
                        limit=5
                    )
                    if my_discoveries:
                        learning_context["my_contributions"] = {
                            "count": len(my_discoveries),
                            "recent": [
                                {
                                    "summary": d.summary[:100] + "..." if len(d.summary) > 100 else d.summary,
                                    "type": d.discovery_type,
                                    "status": d.status
                                }
                                for d in my_discoveries[:3]
                            ],
                            "insight": "Your recent discoveries - build on these"
                        }
                except Exception as e:
                    logger.debug(f"Could not fetch agent's discoveries: {e}")
                
                # 3. Calibration insight - system-wide calibration (auto-collected!)
                try:
                    from src.calibration import calibration_checker
                    
                    # Get calibration stats
                    bin_stats = calibration_checker.bin_stats
                    total = sum(s['count'] for s in bin_stats.values())
                    
                    if total >= 10:  # Need enough data
                        # Calculate overall accuracy
                        total_correct = sum(s.get('actual_correct', 0) for s in bin_stats.values())
                        overall_accuracy = total_correct / total if total > 0 else 0
                        
                        # Find the inverted curve pattern (high confidence = low accuracy)
                        high_conf_bins = ['0.7-0.8', '0.8-0.9', '0.9-1.0']
                        low_conf_bins = ['0.0-0.5', '0.5-0.7']
                        
                        high_conf_total = sum(bin_stats.get(b, {}).get('count', 0) for b in high_conf_bins)
                        high_conf_correct = sum(bin_stats.get(b, {}).get('actual_correct', 0) for b in high_conf_bins)
                        high_conf_accuracy = high_conf_correct / high_conf_total if high_conf_total > 0 else 0
                        
                        low_conf_total = sum(bin_stats.get(b, {}).get('count', 0) for b in low_conf_bins)
                        low_conf_correct = sum(bin_stats.get(b, {}).get('actual_correct', 0) for b in low_conf_bins)
                        low_conf_accuracy = low_conf_correct / low_conf_total if low_conf_total > 0 else 0
                        
                        # Generate insight based on calibration patterns
                        if high_conf_accuracy < low_conf_accuracy - 0.2:
                            cal_insight = "âš ï¸ INVERTED CALIBRATION: High confidence correlates with LOWER accuracy. Consider being more humble."
                        elif abs(high_conf_accuracy - low_conf_accuracy) < 0.1:
                            cal_insight = "âœ… Well calibrated - confidence matches outcomes"
                        else:
                            cal_insight = f"Calibration data available ({total} decisions auto-evaluated)"
                        
                        learning_context["calibration"] = {
                            "total_decisions": total,
                            "overall_accuracy": round(overall_accuracy, 2),
                            "high_confidence_accuracy": round(high_conf_accuracy, 2),
                            "low_confidence_accuracy": round(low_conf_accuracy, 2),
                            "insight": cal_insight,
                            "source": "auto-collected from trajectory outcomes (no human input required)"
                        }
                except Exception as e:
                    logger.debug(f"Could not fetch calibration data: {e}")
                
                # 4. Pattern detection - what's this agent's tendency?
                try:
                    monitor = mcp_server.get_or_create_monitor(agent_id)
                    state = monitor.state
                    
                    patterns = []
                    
                    # Regime pattern
                    if hasattr(state, 'regime'):
                        regime_duration = getattr(state, 'regime_duration', 0)
                        if regime_duration > 5:
                            patterns.append(f"In {state.regime} regime for {regime_duration} updates")
                    
                    # Energy pattern
                    E = response_data.get('metrics', {}).get('E', 0.7)
                    if E > 0.85:
                        patterns.append("High energy - consider channeling into focused work")
                    elif E < 0.5:
                        patterns.append("Low energy - consider taking a step back")
                    
                    # Coherence trend
                    coherence = response_data.get('metrics', {}).get('coherence', 0.5)
                    if coherence < 0.4:
                        patterns.append("Low coherence - your approach may be scattered")
                    elif coherence > 0.8:
                        patterns.append("High coherence - maintaining consistent approach")
                    
                    if patterns:
                        learning_context["patterns"] = {
                            "observations": patterns,
                            "insight": "Patterns from your work - use these for self-awareness"
                        }
                except Exception as e:
                    logger.debug(f"Could not detect patterns: {e}")
                
                # Only include learning_context if we have something meaningful
                if learning_context:
                    response_data["learning_context"] = {
                        "_purpose": "Your own history, surfaced for in-context learning",
                        **learning_context
                    }
            except Exception as e:
                # Never fail the update because of learning context
                logger.debug(f"Could not build learning context: {e}")

            # Optional: compact response mode to reduce cognitive load / token bloat.
            # Priority: per-call response_mode > agent preferences > env var > auto
            # Override per-call with response_mode param or via UNITARES_PROCESS_UPDATE_RESPONSE_MODE env var.
            try:
                import os

                # Check agent preferences first (v2.5.0+)
                agent_verbosity_pref = None
                if meta and hasattr(meta, 'preferences') and meta.preferences:
                    agent_verbosity_pref = meta.preferences.get("verbosity")

                # Priority: per-call > agent pref > env var > auto
                response_mode = (
                    arguments.get("response_mode") or
                    agent_verbosity_pref or
                    os.getenv("UNITARES_PROCESS_UPDATE_RESPONSE_MODE", "auto")
                ).strip().lower()

                # Track if using default for visibility hint
                using_default_mode = not arguments.get("response_mode") and not agent_verbosity_pref

                # AUTO MODE: Adaptive verbosity based on health status (v2 API)
                if response_mode == "auto":
                    # Determine appropriate mode based on health status
                    metrics = response_data.get("metrics", {}) if isinstance(response_data.get("metrics"), dict) else {}
                    health_status = (
                        response_data.get("health_status") or
                        metrics.get("health_status") or
                        response_data.get("status") or
                        "healthy"
                    )

                    # Adaptive logic (v2.5.2):
                    # - healthy â†’ minimal (just action + hint, lowest cognitive load)
                    # - moderate â†’ compact (brief metrics)
                    # - at_risk/critical â†’ standard (interpreted state)
                    if health_status == "healthy":
                        response_mode = "minimal"
                    elif health_status in ("at_risk", "critical"):
                        response_mode = "standard"
                    else:  # moderate or unknown
                        response_mode = "compact"

                # STANDARD MODE: Human-readable interpretation (v2 API)
                if response_mode in ("standard", "interpreted"):
                    from governance_state import GovernanceState
                    from governance_core import State, Theta, DEFAULT_THETA

                    metrics = response_data.get("metrics", {}) if isinstance(response_data.get("metrics"), dict) else {}
                    decision = response_data.get("decision", {}) if isinstance(response_data.get("decision"), dict) else {}

                    # Extract EISV + metadata
                    E = float(metrics.get("E", 0.7))
                    I = float(metrics.get("I", 0.8))
                    S = float(metrics.get("S", 0.1))
                    V = float(metrics.get("V", 0.0))
                    coherence = float(metrics.get("coherence", 0.5))
                    risk_score = metrics.get("latest_risk_score") or metrics.get("risk_score")

                    # Reconstruct minimal GovernanceState for interpretation
                    temp_state = GovernanceState()
                    temp_state.unitaires_state = State(E=E, I=I, S=S, V=V)
                    temp_state.unitaires_theta = Theta(C1=DEFAULT_THETA.C1, eta1=DEFAULT_THETA.eta1)
                    temp_state.coherence = coherence
                    temp_state.decision_history = response_data.get("history", {}).get("decision_history", [])

                    # Get interpreted state
                    interpreted = temp_state.interpret_state(
                        risk_score=risk_score,
                        task_type=task_type
                    )

                    # Build standard response with interpretation
                    response_data = {
                        "success": True,
                        "agent_id": response_data.get("agent_id"),
                        "decision": decision.get("action") or response_data.get("status"),
                        "state": interpreted,
                        "metrics": {
                            "E": E,
                            "I": I,
                            "S": S,
                            "V": V,
                            "coherence": coherence,
                            "risk_score": risk_score,
                        },
                        "sampling_params": response_data.get("sampling_params"),
                        "_mode": "standard",
                        "_raw_available": "Use response_mode='full' to see complete metrics"
                    }

                # MINIMAL MODE: Bare essentials - action + proprioceptive margin
                elif response_mode == "minimal":
                    decision = response_data.get("decision", {}) if isinstance(response_data.get("decision"), dict) else {}
                    action = decision.get("action", "continue")
                    margin = decision.get("margin")  # comfortable/tight/critical
                    nearest_edge = decision.get("nearest_edge")  # risk/coherence/void

                    response_data = {
                        "action": action,
                        "_mode": "minimal"
                    }
                    # Include margin for proprioceptive awareness (not noise - actionable signal)
                    if margin:
                        response_data["margin"] = margin
                    if nearest_edge:
                        response_data["nearest_edge"] = nearest_edge
                    if using_default_mode:
                        response_data["_tip"] = "Set verbosity: update_agent_metadata(preferences={'verbosity':'minimal'})"

                # COMPACT MODE: Minimal fields (existing behavior)
                elif response_mode in ("compact", "lite"):
                    metrics = response_data.get("metrics", {}) if isinstance(response_data.get("metrics"), dict) else {}
                    decision = response_data.get("decision", {}) if isinstance(response_data.get("decision"), dict) else {}

                    # Canonical risk_score: prefer point-in-time latest_risk_score when present, else risk_score.
                    canonical_risk = metrics.get("latest_risk_score")
                    if canonical_risk is None:
                        canonical_risk = metrics.get("risk_score")

                    compact_metrics = {
                        "E": metrics.get("E"),
                        "I": metrics.get("I"),
                        "S": metrics.get("S"),
                        "V": metrics.get("V"),
                        "coherence": metrics.get("coherence"),
                        "risk_score": canonical_risk,
                        "phi": metrics.get("phi"),
                        "verdict": metrics.get("verdict"),
                        "lambda1": metrics.get("lambda1"),
                        "health_status": metrics.get("health_status"),
                        "health_message": metrics.get("health_message"),
                    }

                    # Strip risk duplicates inside decision payload if present.
                    compact_decision = {
                        "action": decision.get("action"),
                        "reason": decision.get("reason"),
                        "require_human": decision.get("require_human"),
                        "margin": decision.get("margin"),  # comfortable/tight/critical
                        "nearest_edge": decision.get("nearest_edge"),  # risk/coherence/void
                    }

                    health_status = response_data.get("health_status") or compact_metrics.get("health_status") or response_data.get("status")
                    coherence = compact_metrics.get("coherence")
                    risk_val = compact_metrics.get("risk_score")
                    action = compact_decision.get("action") or response_data.get("status")
                    summary = f"{action} | health={health_status} | coherence={coherence} | risk_score={risk_val}"

                    response_data = {
                        "success": True,
                        "agent_id": response_data.get("agent_id"),
                        "status": response_data.get("status"),
                        "health_status": health_status,
                        "health_message": response_data.get("health_message"),
                        "decision": compact_decision,
                        "metrics": compact_metrics,
                        "sampling_params": response_data.get("sampling_params"),
                        "summary": summary,
                        "_mode": "compact",
                    }

                    # Add visibility hint for agents using default mode (v2.5.0+)
                    if using_default_mode:
                        response_data["_tip"] = "Verbosity options: response_mode='minimal'|'compact'|'full', or set permanently via update_agent_metadata(preferences={'verbosity':'minimal'})"
                    
                    # EXTREME LITE MODE: Strip optional context for minimal/compact modes
                    # Reduces cognitive load by removing noise once agent is established
                    if response_mode in ("minimal", "compact"):
                        # Always strip static labels and notes
                        response_data.pop("eisv_labels", None)
                        response_data.pop("sampling_params_note", None)
                        
                        # Strip context unless critical/new
                        if not is_new_agent:
                            response_data.pop("learning_context", None)
                            response_data.pop("relevant_discoveries", None)
                            response_data.pop("onboarding", None)
                            response_data.pop("welcome", None)
                            # Only show API key hint if it was just generated/retrieved
                            if not (key_was_generated or api_key_auto_retrieved):
                                response_data.pop("api_key_hint", None)
                                response_data.pop("_onboarding", None)
            except Exception:
                pass

            # Return immediately - wrap in try/except to catch serialization errors
            # This prevents server crashes if serialization fails
            try:
                # Pass agent_uuid explicitly to ensure agent_signature matches the correct identity
                return success_response(response_data, agent_id=agent_uuid, arguments=arguments)
            except Exception as serialization_error:
                # If serialization fails, return minimal error response
                logger.error(f"Failed to serialize response: {serialization_error}", exc_info=True)
                # Return minimal response to prevent server crash
                import json
                from mcp.types import TextContent
                # Extract metrics once to avoid 6 repeated .get() calls
                metrics = result.get("metrics", {})
                return [TextContent(
                    type="text",
                    text=json.dumps({
                        "success": True,
                        "status": result.get("status", "unknown"),
                        "decision": result.get("decision", {}),
                        "metrics": {
                            "E": float(metrics.get("E", 0)),
                            "I": float(metrics.get("I", 0)),
                            "S": float(metrics.get("S", 0)),
                            "V": float(metrics.get("V", 0)),
                            "coherence": float(metrics.get("coherence", 0)),
                            "risk_score": float(metrics.get("risk_score", 0))
                        },
                        "sampling_params": result.get("sampling_params", {}),
                        "_warning": "Response serialization had issues - some fields may be missing"
                    })
                )]
    except TimeoutError as e:
        # Lock acquisition failed even after automatic retries and cleanup
        # Try one more aggressive cleanup attempt (async to avoid blocking error response)
        try:
            from src.lock_cleanup import cleanup_stale_state_locks
            project_root = Path(__file__).parent.parent.parent
            # Run cleanup in executor to avoid blocking error response
            cleanup_result = await loop.run_in_executor(
                None,
                cleanup_stale_state_locks,
                project_root,
                60.0,  # max_age_seconds
                False  # dry_run
            )
            if cleanup_result['cleaned'] > 0:
                logger.info(f"Auto-recovery: Cleaned {cleanup_result['cleaned']} stale lock(s) after timeout")
        except Exception as cleanup_error:
            logger.warning(f"Could not perform emergency lock cleanup: {cleanup_error}")
        
        return [error_response(
            f"Failed to acquire lock for agent '{agent_id}' after automatic retries and cleanup. "
            f"This usually means another active process is updating this agent. "
            f"The system has automatically cleaned stale locks. If this persists, try: "
            f"1) Wait a few seconds and retry, 2) Check for other Cursor/Claude sessions, "
            f"3) Use cleanup_stale_locks tool, or 4) Restart Cursor if stuck."
        )]
    except PermissionError as e:
        # Authentication failed
        return [error_response(
            f"Authentication failed: {str(e)}",
            details={"error_type": "authentication_error"},
            recovery={
                "action": "Provide a valid API key for this agent",
                "related_tools": ["get_agent_api_key"],
                "workflow": "1. Use get_agent_api_key to retrieve your key 2. Include api_key in your request"
            }
        )]
    except ValueError as e:
        # Loop detected or validation error
        error_msg = str(e)
        if "Self-monitoring loop detected" in error_msg:
            return [error_response(
                error_msg,
                details={"error_type": "loop_detected"},
                recovery={
                    "action": "Wait for cooldown period to expire before retrying",
                    "related_tools": ["get_governance_metrics"],
                    "workflow": "1. Check current agent status 2. Wait for cooldown to expire 3. Retry with different parameters"
                }
            )]
        else:
            return [error_response(
                f"Validation error: {error_msg}",
                details={"error_type": "validation_error"},
                recovery={
                    "action": "Check your parameters and try again",
                    "related_tools": ["health_check"],
                    "workflow": "1. Verify all parameters are valid 2. Check system health 3. Retry"
                }
            )]
    except Exception as e:
        # Catch any other unexpected errors to prevent disconnection
        logger.error(f"Unexpected error in process_agent_update: {e}", exc_info=True)
        return [error_response(
            f"An unexpected error occurred: {str(e)}",
            details={"error_type": "unexpected_error"},
            recovery={
                "action": "Check server logs for details. If this persists, try restarting the MCP server",
                "related_tools": ["health_check", "get_server_info"],
                "workflow": "1. Check system health 2. Review server logs 3. Restart MCP server if needed"
            }
        )]

